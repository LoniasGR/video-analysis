{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eEveggvc1aGi"
   },
   "source": [
    "# Εκτίμηση κίνησης σε Βίντεο"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqKWsv3q6D4F"
   },
   "source": [
    "## Ανοιγμα και επισκόπηση βίντεο\n",
    "Διαχειριζόμαστε αρχείο βίντεο με OpenCV, με τον ίδιο τρόπο που διαχειριζόμαστε στατικές εικόνες (ή αρχεία εικόνων).\n",
    "\n",
    "Η λογική μας είναι per-frame (ανά καρέ). Ανοίγουμε αρχικά το αρχείο video με την μέθοδο `cv2.VideoCapture()`, η οποία δέχεται σαν όρισμα ένα από τα παρακάτω:\n",
    "\n",
    "\n",
    "*   path για το αρχείο video\n",
    "*   device για capturing (id της κάμερας)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYts15w33F3p"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/highgui/src/window.cpp:626: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Carbon support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2a4e20e31efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/highgui/src/window.cpp:626: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Carbon support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# video.mp4: input video\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "while (cap.isOpened()):\n",
    "  ret, frame = cap.read()\n",
    "\n",
    "  cv2.imshow(\"A simple video player\", frame)\n",
    "\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxmU0vql4LwN"
   },
   "source": [
    "Στον παραπάνω κώδικα, η συνάρτηση `read()` της κλάσης VideoCapture επιστρέφει το επόμενο frame, όσο υπάρχουν frames στο αρχείο ή στο stream. Η `ret` αποθηκεύει μια bool τιμή σχετική με το αποτέλεσμα.\n",
    "\n",
    "Συμπεριφερόμαστε στο frame σαν σε μια κανονική εικόνα. Μπορούμε να την επεξεργαστούμε με OpenCV, numpy, scikit-image κλπ.\n",
    "\n",
    "Η `cv2.waitKey()` περιμένει τον αριθμό των milliseconds που θα της δώσουμε, ή μέχρι να πατήσουμε το πλήκτρο που ορίζουμε στο `ord()` για να προχωρήσει στο επόμενο καρέ ή να κόψει το while-loop αντίστοιχα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cvWWnnI6Ant"
   },
   "source": [
    "## Video properties\n",
    "\n",
    "Με την `get()` της κλάσης VideoCapture, μπορούμε να πάρουμε πληροφορίες για το βίντεο, χρήσιμες για τη συνέχεια. Η μέθοδος αυτή δέχεται σαν όρισμα έναν ακέραιο ή ένα flag της OpenCV, που υποδηλώνει το property που θέλουμε να διαβάσουμε:\n",
    "\n",
    "*   **cv2.CAP_PROP_FPS**: μας επιστρέφει τα FPS του βίντεο\n",
    "*   **cv2.CAP_PROP_FRAME_WIDTH** και **cv2.CAP_PROP_FRAME_HEIGHT**: μας επιστρέφει το width και το height (columns και rows) του κάθε καρέ. Εναλλακτικά μπορούμε να χρησιμοποιήσουμε τη `frame.shape`.\n",
    "\n",
    "Μπορείτε να βρείτε μια εξαντλητική λίστα των properties [εδώ](https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get). Στις τελευταίες εκδόσεις της python OpenCV, αφαιρείτε το αρχικό \"CV_\" από τα ονόματα των macros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "_9WFuVwp7q0y",
    "outputId": "4479669b-ae99-4832-ffdb-0236b7a17294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n",
      "1280.0\n",
      "720.0\n",
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"shibuya.mp4\")\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bze1kpsQ9alG"
   },
   "source": [
    "# Optical flow\n",
    "Μέχρι στιγμής, έχουμε δει εφαρμογές που επεξεργάζονται μια εικόνα χωρικά, στο ίδιο frame. Τις ίδιες εφαρμογές μπορούμε να τις επεκτείνουμε και στο video.\n",
    "\n",
    "Βέβαια, το video περιλαμβάνει και χρονική πληροφορίά. Δεν πρόκειται απλά για μια αλληλουχία άσχετων εικόνων. Έτσι, χρειαζόμαστε τρόπους για να ανιγνεύσουμε αυτή τη σχέση ανάμεσα στα frames.\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=16_hfIQ5fr3S74Nz312UlufB0x4yfGs6f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_T99iKh-x02"
   },
   "source": [
    "### Tι είναι το Optical flow\n",
    "To πρόβλημα του optical flow μπορεί να οριστεί ως εξής:\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1g0AKcxrxieA76espjs7ZeofFQjSfcxqZ\" width=\"70%\">\n",
    "\n",
    "όπου, ανάμεσα σε διαδοχικά frames, εκφράζουμε την τιμή φωτεινότητας (I) συναρτήσει του χώρου (x,y) και του χρόνου (t).\n",
    "$$I(x,y,t)=I(x+δx,y+δy,t+δt) $$\n",
    "\n",
    "που με προσέγγιση Taylor γίνεται: $I(x+δx,y+δy,t+δt)=I(x,y,t)+\\frac{\\partial(I)}{\\partial(x)}δx+\\frac{\\partial(I)}{\\partial(y)}δy+\\frac{\\partial(I)}{\\partial(t)}δt+...$ \n",
    "ή $\\frac{\\partial(I)}{\\partial(x)}u+\\frac{\\partial(I)}{\\partial(y)}v+\\frac{\\partial(I)}{\\partial(t)}=0$\n",
    "\n",
    "όπου $u=\\frac{dx}{dt}$ και $v=\\frac{dy}{dt}$, $\\frac{dI}{dx}$, $\\frac{dI}{dy}$ και $\\frac{dI}{dt}$ είναι οι παράγωγοι της εικόνας ως προς τον οριζόντιο άξονα, τον κάθετο άξονα και το χρόνο. \n",
    "\n",
    "\n",
    "Έτσι, το πρόβλημα του optical flow καταλήγει στο να βρούμε τις \"ταχύτητες\" $u (\\frac{dx}{dt})$ και $v (\\frac{dy}{dt})$  για να καθορίσουμε την κίνηση στο χρόνο."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pg10RqUPBzPU"
   },
   "source": [
    "### Εύρεση χαρακτηριστικών για tracking.\n",
    "\n",
    "Υπάρχουν δύο \"σχολές\" optical flow:\n",
    "\n",
    "\n",
    "*   **Sparse optical flow (Αραιή οπτική ροή):** Παρακολούθηση συγκεκριμένων χαρακτηριστικών ενός frame στην πορεία του βίντεο\n",
    "*   **Dense optical flow ((Πυκνή οπτική ροή):** Παρακολούθηση όλων των pixels του frame, στην πορεία του βίντεο\n",
    "\n",
    "Η δεύτερη είναι πιο ακριβής αλλά και πιο υπολογιστικά ακριβή."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOwiEmkcB8K_"
   },
   "source": [
    "#### Sparse optical flow σε Shi-Tomasi features\n",
    "\n",
    "Για την εφαρμογή του optical flow, παρακολουθούμε μόνο την κίνηση ενός σετ χαρακτηριστικών. Tα features στις εικόνες είναι σημεία ενδιαφέροντος που παρουσιάζουν πλούσιες πληροφορίες περιεχομένου εικόνας. Για παράδειγμα, τέτοια features μπορεί να είναι σημεία στην εικόνα που είναι αμετάβλητα στη μετάφραση, την κλίμακα, την περιστροφή και τις αλλαγές έντασης όπως οι γωνίες.\n",
    "\n",
    "Ο Shi-Tomasi Corner Detector είναι πολύ παρόμοιος με τον γνωστό Harris Corner Detector. Ακολουθεί την παρακάτω διαδικασία:\n",
    "\n",
    "*   Καθορισμός παραθύρων με μεγαλες κλίσεις (διακυμάνσεις στην ένταση της εικόνας) όταν υπάρχει μετατόπιση τόσο κατά την διεύθυνση του x και του y.\n",
    "\n",
    "*   Για κάθε παράθυρο, υπολογίστε το score R\n",
    "*   Ανάλογα με την τιμή του R, κάθε παράθυρο ταξινομείται ως επίπεδη περιοχή (δίχως διακυμάνσεις στην φωτεινότητα), άκρο ή γωνία.\n",
    "\n",
    "\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1Egv5GSlo4z8xR5S6_oHSrWC0DufFEvle)\n",
    "\n",
    "O Shi-Tomasi detector θεωρείται ότι βελτιώνει τον Harris detector καθώς προσφέρει μια πιο robust και uniform αναπαράσταση των σχημάτων.\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1gItLF4m0CujefFkusEwGmeNsT5kuq6Lw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5jzx0N3Rrgq"
   },
   "source": [
    "### Ο αλγόριθμος Lucas-Kanade\n",
    "\n",
    "Ο Lucas και ο Kanade πρότειναν μια αποτελεσματική τεχνική για την εκτίμηση της κίνησης των ενδιαφερόντων χαρακτηριστικών συγκρίνοντας δύο διαδοχικά καρέ. Η μέθοδος Lucas-Kanade λειτουργεί με τις ακόλουθες παραδοχές:\n",
    "\n",
    "1. Δύο διαδοχικά καρέ χωρίζονται με μια μικρή αύξηση χρόνου (dt) έτσι ώστε τα αντικείμενα να μην εκτοπίζονται σημαντικά (με άλλα λόγια, η μέθοδος λειτουργεί καλύτερα με αντικείμενα με αργή κίνηση).\n",
    "2. Ένα πλαίσιο απεικονίζει μια «φυσική» σκηνή αντικειμένων με αποχρώσεις του γκρι που αλλάζουν ομαλά.\n",
    "\n",
    "Kάτω από αυτές τις υποθέσεις, μπορούμε να πάρουμε ένα μικρό παράθυρο 3x3 (γειτονιά) γύρω από τα χαρακτηριστικά που εντοπίστηκαν από τον Shi-Tomasi και να υποθέσουμε ότι και τα εννέα σημεία έχουν την ίδια κίνηση.\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1BiXITXWrPH-BWMN3bRSd_Iu0AtATt09y)\n",
    "\n",
    "Αυτό είναι ένα set από 9 εξισώσεις, όπως αυτή που είδαμε στην αρχή:\n",
    "\n",
    "$\\begin{matrix}\n",
    "  I_x(q_1)V_x+I_y(q_1)V_y=I_t(q_1)\\\\\n",
    "  I_x(q_2)V_x+I_y(q_2)V_y=I_t(q_2)\\\\\n",
    "  \\vdots\\\\\n",
    "  I_x(q_n)V_x+I_y(q_n)V_y=I_t(q_n)\\\\\n",
    " \\end{matrix}$\n",
    "\n",
    "\n",
    "Σε μορφή συστήματος, αυτό γίνεται:\n",
    "\n",
    "\n",
    "$A=\\begin{bmatrix}\n",
    "  I_x(q_1)&&I_y(q_1)\\\\\n",
    "  I_x(q_2)&&I_y(q_2)\\\\\n",
    "  \\vdots&&\\vdots\\\\\n",
    "  I_x(q_n)&&I_y(q_n)\\\\\n",
    " \\end{bmatrix}\\quad \\quad$   $ u=\\begin{bmatrix}V_x\\\\ V_y\\end{bmatrix}\\quad \\quad$   $ b=\\begin{bmatrix}-I_t(q_1)\\\\-I_t(q_2)\\\\ \\vdots \\\\-I_t(q_n)\\end{bmatrix}$\n",
    "\n",
    "Ενώ στην αρχή είχαμε δύο αγνώστους (u και v) και μια εξίσωση, τώρα έχουμε δύο αγνώστους και 9 εξισώσεις!\n",
    "\n",
    "Χρησιμοποιούμε least squares fitting για να λύσουμε το πρόβλημα του over-determination:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "  V_x\\\\\n",
    "  V_y\\\\\n",
    "\\end{bmatrix} \\quad = \n",
    "\\quad \\begin{bmatrix}\\sum_iI_x(q_i)^2 && \\sum_iI_x(q_i)I_y(q_i)\\\\\\sum_iI_y(q_i)I_x(q_i) && \\sum_iI_y(q_i)^2 \\end{bmatrix}\n",
    "\\quad \\begin{bmatrix}-\\sum_iI_x(q_i)I_t(q_i)\\\\-\\sum_iI_y(q_i)I_t(q_i)\\end{bmatrix}$\n",
    "\n",
    "\n",
    "Με λίγα λόγια, εντοπίζουμε μερικά ενδιαφέροντα χαρακτηριστικά για παρακολούθηση και υπολογίζουμε επαναληπτικά τα διανύσματα optical flow αυτών των σημείων. Ωστόσο, η υιοθέτηση της μεθόδου Lucas-Kanade λειτουργεί μόνο για μικρές κινήσεις (από την αρχική μας υπόθεση) και αποτυγχάνει όταν υπάρχει μεγάλη κίνηση.\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1tkw2Btbi7ZdZg_mMk4shSYvieb1coxip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PCzF0cl8YYch",
    "outputId": "9b007f97-a75b-4857-c94e-1c76c72c862e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py:2142: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if v not in values:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c0e3e5a41b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Opens a new window and displays the output frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse optical flow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Frames are read by intervals of 10 milliseconds. The programs breaks out of the while loop when the user presses the 'q' key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5611\u001b[0m         im = mimage.AxesImage(self, cmap, norm, interpolation, origin, extent,\n\u001b[1;32m   5612\u001b[0m                               \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5613\u001b[0;31m                               resample=resample, **kwargs)\n\u001b[0m\u001b[1;32m   5614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5615\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ax, cmap, norm, interpolation, origin, extent, filternorm, filterrad, resample, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m         )\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ax, cmap, norm, interpolation, origin, filternorm, filterrad, resample, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m                  ):\n\u001b[1;32m    247\u001b[0m         \u001b[0mmartist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScalarMappable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mouseover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morigin\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, norm, cmap)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m#: The Colormap instance of this ScalarMappable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;31m#: The last colorbar associated with this ScalarMappable. May be None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cm.py\u001b[0m in \u001b[0;36mget_cmap\u001b[0;34m(name, lut)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColormap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_in_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlut\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcmap_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_in_list\u001b[0;34m(_values, **kwargs)\u001b[0m\n\u001b[1;32m   2143\u001b[0m             raise ValueError(\n\u001b[1;32m   2144\u001b[0m                 \u001b[0;34m\"{!r} is not a valid value for {}; supported values are {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2145\u001b[0;31m                 .format(v, k, ', '.join(map(repr, values))))\n\u001b[0m\u001b[1;32m   2146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array([[[ 88,  98,  95],\n        [ 52,  62,  59],\n        [ 57,  67,  64],\n        ...,\n        [ 46,  48,  64],\n        [ 41,  39,  53],\n        [ 36,  34,  48]],\n\n       [[ 64,  74,  71],\n        [ 39,  49,  46],\n        [ 57,  67,  64],\n        ...,\n        [ 38,  40,  56],\n        [ 36,  34,  48],\n        [ 36,  34,  48]],\n\n       [[ 41,  51,  48],\n        [ 22,  32,  29],\n        [ 48,  58,  55],\n        ...,\n        [ 31,  33,  49],\n        [ 35,  33,  47],\n        [ 35,  33,  47]],\n\n       ...,\n\n       [[125, 117, 112],\n        [126, 118, 113],\n        [129, 121, 116],\n        ...,\n        [ 91,  91,  98],\n        [ 85,  85,  92],\n        [ 79,  79,  86]],\n\n       [[125, 117, 112],\n        [126, 118, 113],\n        [129, 121, 116],\n        ...,\n        [100,  98, 110],\n        [ 94,  92, 104],\n        [ 90,  88, 100]],\n\n       [[125, 117, 112],\n        [126, 118, 113],\n        [129, 121, 116],\n        ...,\n        [112, 110, 122],\n        [112, 110, 122],\n        [108, 106, 118]]], dtype=uint8) is not a valid value for name; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'oc..."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for Shi-Tomasi corner detection\n",
    "feature_params = dict(maxCorners = 300, qualityLevel = 0.2, minDistance = 2, blockSize = 7)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize = (15,15), maxLevel = 2, criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "cap = cv.VideoCapture(\"shibuya.mp4\")\n",
    "\n",
    "color = (0, 255, 0)\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "\n",
    "# Converts frame to grayscale because we only need the luminance channel for detecting edges - less computationally expensive\n",
    "prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Finds the strongest corners in the first frame by Shi-Tomasi method - we will track the optical flow for these corners\n",
    "prev = cv.goodFeaturesToTrack(prev_gray, mask = None, **feature_params)\n",
    "\n",
    "# Creates an image filled with zero intensities with the same dimensions as the frame - for later drawing purposes\n",
    "mask = np.zeros_like(first_frame)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculates sparse optical flow by Lucas-Kanade method\n",
    "    next, status, error = cv.calcOpticalFlowPyrLK(prev_gray, gray, prev, None, **lk_params)\n",
    "\n",
    "    # Selects good feature points for previous position\n",
    "    good_old = prev[status == 1]\n",
    "\n",
    "    # Selects good feature points for next position\n",
    "    good_new = next[status == 1]\n",
    "\n",
    "    # Draws the optical flow tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        # a, b = coordinates of new point\n",
    "        a, b = new.ravel()\n",
    "\n",
    "        # a, b = coordinates of old point\n",
    "        c, d = old.ravel()\n",
    "\n",
    "        # Draws line between new and old position with green color and 2 thickness\n",
    "        mask = cv.line(mask, (a, b), (c, d), color, 2)\n",
    "\n",
    "        # Draws filled circle (thickness of -1) at new position with green color and radius of 3\n",
    "        frame = cv.circle(frame, (a, b), 3, color, -1)\n",
    "\n",
    "    # Overlays the optical flow tracks on the original frame\n",
    "    output = cv.add(frame, mask)\n",
    "\n",
    "    # Updates previous frame\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    # Updates previous good feature points\n",
    "    prev = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "    # Opens a new window and displays the output frame\n",
    "    plt.imshow(\"sparse optical flow\", output)\n",
    "\n",
    "    # Frames are read by intervals of 10 milliseconds. The programs breaks out of the while loop when the user presses the 'q' key\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# The following frees up resources and closes all windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab6_Motion_estimation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
